{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/adrian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import tiktoken\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenCounter:\n",
    "    def __init__(self):\n",
    "        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.total_tokens = {\n",
    "            \"embedding\": 0,\n",
    "            \"retrieval\": 0\n",
    "        }\n",
    "\n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        return len(self.encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(self, chunk_size=500, chunk_overlap=50):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "        )\n",
    "        self.model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
    "        \n",
    "    def process_documents(self, dataset, num_docs=10):\n",
    "        documents = []\n",
    "        for i in range(num_docs):\n",
    "            doc = dataset['train'][i]\n",
    "            full_text = f\"Title: {doc['title']}\\n\\nContent: {doc['text']}\"\n",
    "            chunks = self.text_splitter.split_text(full_text)\n",
    "            documents.extend(chunks)\n",
    "            \n",
    "        # Create embeddings and BM25 index\n",
    "        embeddings = self.model.encode(documents, normalize_embeddings=True)\n",
    "        tokenized_corpus = [word_tokenize(doc.lower()) for doc in documents]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        \n",
    "        return documents, embeddings, bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRetriever:\n",
    "    def __init__(self, documents, embeddings, bm25, model):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "        self.bm25 = bm25\n",
    "        self.model = model\n",
    "\n",
    "        self.token_counter = TokenCounter()\n",
    "        self.token_stats = {\n",
    "            \"total_query_tokens\": 0,\n",
    "            \"total_retrieved_tokens\": 0,\n",
    "            \"queries_processed\": 0\n",
    "        }\n",
    "    \n",
    "    def retrieve(self, query, top_k=4):\n",
    "        query_tokens = self.token_counter.count_tokens(query)\n",
    "        self.token_stats[\"total_query_tokens\"] += query_tokens\n",
    "\n",
    "        semantic_results = self._semantic_search(query, top_k)\n",
    "        bm25_results = self._bm25_search(query, top_k)\n",
    "        final_results = self._rank_fusion(semantic_results, bm25_results)\n",
    "\n",
    "        retrieved_docs = [self.documents[doc_id] for doc_id, _ in final_results[:top_k]]\n",
    "        retrieved_tokens = sum(self.token_counter.count_tokens(doc) for doc in retrieved_docs)\n",
    "        self.token_stats[\"total_retrieved_tokens\"] += retrieved_tokens\n",
    "        \n",
    "        self.token_stats[\"queries_processed\"] += 1\n",
    "\n",
    "\n",
    "        print(f\"\\nRetrieval Operation Stats (Query #{self.token_stats['queries_processed']}):\")\n",
    "        print(f\"Query tokens: {query_tokens}\")\n",
    "        print(f\"Retrieved document tokens: {retrieved_tokens}\")\n",
    "        print(f\"Average tokens per retrieved document: {retrieved_tokens / len(retrieved_docs):.1f}\")\n",
    "\n",
    "        return retrieved_docs\n",
    "    \n",
    "    def get_token_stats(self):\n",
    "        stats = self.token_stats.copy()\n",
    "        if stats[\"queries_processed\"] > 0:\n",
    "            stats[\"average_query_tokens\"] = stats[\"total_query_tokens\"] / stats[\"queries_processed\"]\n",
    "            stats[\"average_retrieved_tokens\"] = stats[\"total_retrieved_tokens\"] / stats[\"queries_processed\"]\n",
    "        return stats\n",
    "    \n",
    "    def _semantic_search(self, query, top_k):\n",
    "        query_embedding = self.model.encode(\n",
    "            f\"Represent this sentence for searching relevant passages: {query}\", \n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "        similarities = query_embedding @ self.embeddings.T\n",
    "        top_indices = np.argpartition(similarities, -top_k)[-top_k:]\n",
    "        return [(idx, similarities[idx]) for idx in top_indices]\n",
    "    \n",
    "    def _bm25_search(self, query, top_k):\n",
    "        tokenized_query = word_tokenize(query.lower())\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        top_indices = np.argpartition(scores, -top_k)[-top_k:]\n",
    "        return [(idx, scores[idx]) for idx in top_indices]\n",
    "    \n",
    "    def _rank_fusion(self, semantic_results, bm25_results, k=60):\n",
    "        scores = {}\n",
    "        for results in [semantic_results, bm25_results]:\n",
    "            for rank, (doc_id, score) in enumerate(sorted(results, key=lambda x: x[1], reverse=True)):\n",
    "                scores[doc_id] = scores.get(doc_id, 0) + 1.0 / (rank + k)\n",
    "        return sorted(scores.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseGenerator:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=os.getenv(\"OPENROUTER_KEY\"),\n",
    "        )\n",
    "    \n",
    "    def generate(self, query, context):\n",
    "        prompt = f\"\"\"Please provide a direct answer to the question using only the information from the provided context. If the information is not available in the context, please state that.\n",
    "        Question: {query}\n",
    "        Context: {context}\n",
    "        Ensure your response is clear and concise. Do not suggest search queries or discuss how to search for information.\"\"\"\n",
    "        \n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-chat\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n",
      "Processing documents\n",
      "Documents processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the significance of Baghdad Internatio...</td>\n",
       "      <td>The significance of Baghdad International Airp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does natural selection explain the develop...</td>\n",
       "      <td>Natural selection explains the development of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are some key milestones in Halsey's music...</td>\n",
       "      <td>Key milestones in Halsey's music career includ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  \\\n",
       "0  What is the significance of Baghdad Internatio...   \n",
       "1  How does natural selection explain the develop...   \n",
       "2  What are some key milestones in Halsey's music...   \n",
       "\n",
       "                                            Response  \n",
       "0  The significance of Baghdad International Airp...  \n",
       "1  Natural selection explains the development of ...  \n",
       "2  Key milestones in Halsey's music career includ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"pszemraj/simple_wikipedia\")\n",
    "print(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing documents\n",
      "Documents processed\n"
     ]
    }
   ],
   "source": [
    "# Process documents\n",
    "processor = DocumentProcessor()\n",
    "print(\"Processing documents\")\n",
    "processor.process_documents(dataset)\n",
    "print(\"Documents processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TokenCounter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize retriever and generator\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mHybridRetriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbm25\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m generator \u001b[38;5;241m=\u001b[39m ResponseGenerator()\n",
      "Cell \u001b[0;32mIn[47], line 8\u001b[0m, in \u001b[0;36mHybridRetriever.__init__\u001b[0;34m(self, documents, embeddings, bm25, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm25 \u001b[38;5;241m=\u001b[39m bm25\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_counter \u001b[38;5;241m=\u001b[39m \u001b[43mTokenCounter\u001b[49m()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_stats \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_query_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_retrieved_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TokenCounter' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize retriever and generator\n",
    "retriever = HybridRetriever(documents, embeddings, bm25, processor.model)\n",
    "generator = ResponseGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries\n",
    "queries = [\n",
    "    # Basic Factual\n",
    "    \"Who was Albert Einstein and what is he known for?\",\n",
    "    \"What is the capital of France and what landmarks is it famous for?\",\n",
    "    \"When did World War II begin and end?\",\n",
    "    \"What is photosynthesis and how does it work?\",\n",
    "    \"Who wrote Romeo and Juliet and what is the play about?\",\n",
    "    \n",
    "    # Multi-hop\n",
    "    # \"How did the Industrial Revolution affect both urban development and working conditions?\",\n",
    "    # \"What connection exists between the Renaissance and the Scientific Revolution?\",\n",
    "    # \"How did ancient Greek democracy influence modern governmental systems?\",\n",
    "    \n",
    "    # # Comparative\n",
    "    # \"What are the main differences between DNA and RNA?\",\n",
    "    # \"How do classical and quantum physics differ?\",\n",
    "    # \"Compare the American and French Revolutions: what were their causes and outcomes?\",\n",
    "    \n",
    "    # # Time-Based\n",
    "    # \"What major events occurred during the 1960s Space Race?\",\n",
    "    # \"How did transportation evolve from the 19th to the 20th century?\",\n",
    "    # \"What were the key developments in computer technology during the 1990s?\",\n",
    "    \n",
    "    # # Scientific\n",
    "    # \"How does gravity affect planetary motion?\",\n",
    "    # \"What role do enzymes play in digestion?\",\n",
    "    # \"How does climate change affect global weather patterns?\",\n",
    "    \n",
    "    # # Historical\n",
    "    # \"What caused the fall of the Roman Empire?\",\n",
    "    # \"How did the Black Death impact medieval Europe?\",\n",
    "    # \"What were the major achievements of ancient Egypt?\",\n",
    "    \n",
    "    # # Edge Cases\n",
    "    # \"What is the Revolution?\", \n",
    "    # \"What happened in Azerbaijan in 1832?\",  \n",
    "    # \"What are the outcomes of the 2024 Olympics?\",\n",
    "    # \"How did mathematics influence both art and music?\",\n",
    "    \n",
    "    # # Lists and Specifics\n",
    "    # \"What are the main types of renewable energy?\",\n",
    "    # \"How many planets are in our solar system and what are their sizes?\",\n",
    "    # \"When were the major pyramids of Egypt built?\",\n",
    "    # \"Who were the key leaders during World War II?\",\n",
    "    \n",
    "    # # Complex Reasoning\n",
    "    # \"How did various inventions during the Industrial Revolution connect to create modern factories?\",\n",
    "    # \"What relationship exists between climate, geography, and the development of ancient civilizations?\",\n",
    "    # \"How did different philosophical movements influence political changes throughout history?\"\n",
    "]\n",
    "    \n",
    "# Process queries and display results\n",
    "results = []\n",
    "for query in queries:\n",
    "    retrieved_docs = retriever.retrieve(query)\n",
    "    context = \"\\n\\n\".join(retrieved_docs)\n",
    "    response = generator.generate(query, context)\n",
    "    results.append({'Query': query, 'Response': response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was Albert Einstein and what is he known for?</td>\n",
       "      <td>The provided context does not mention Albert E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of France and what landmar...</td>\n",
       "      <td>The capital of France is Paris. Paris is famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did World War II begin and end?</td>\n",
       "      <td>The provided context does not explicitly state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is photosynthesis and how does it work?</td>\n",
       "      <td>The context provided does not contain any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who wrote Romeo and Juliet and what is the pla...</td>\n",
       "      <td>The context does not provide information about...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  \\\n",
       "0  Who was Albert Einstein and what is he known for?   \n",
       "1  What is the capital of France and what landmar...   \n",
       "2               When did World War II begin and end?   \n",
       "3       What is photosynthesis and how does it work?   \n",
       "4  Who wrote Romeo and Juliet and what is the pla...   \n",
       "\n",
       "                                            Response  \n",
       "0  The provided context does not mention Albert E...  \n",
       "1  The capital of France is Paris. Paris is famou...  \n",
       "2  The provided context does not explicitly state...  \n",
       "3  The context provided does not contain any info...  \n",
       "4  The context does not provide information about...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HybridRetriever' object has no attribute 'get_token_stats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get final token statistics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token_stats\u001b[49m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Token Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal queries processed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueries_processed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HybridRetriever' object has no attribute 'get_token_stats'"
     ]
    }
   ],
   "source": [
    "# Get final token statistics\n",
    "stats = retriever.get_token_stats()\n",
    "print(f\"\\nFinal Token Statistics:\")\n",
    "print(f\"Total queries processed: {stats['queries_processed']}\")\n",
    "print(f\"Total query tokens: {stats['total_query_tokens']}\")\n",
    "print(f\"Total retrieved tokens: {stats['total_retrieved_tokens']}\")\n",
    "print(f\"Average tokens per query: {stats['average_query_tokens']:.1f}\")\n",
    "print(f\"Average tokens per retrieval: {stats['average_retrieved_tokens']:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
